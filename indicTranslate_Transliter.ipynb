{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indicTranslate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_d-VqqEAdMN9MK8eILnfxXEnuZ6C0MSc",
      "authorship_tag": "ABX9TyOJdkBcYR1dFq89Ni5lqLVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/readall/indiatranslator/blob/main/indicTranslate_Transliter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kh_aJ5Fl0Mz"
      },
      "source": [
        "%%bash\n",
        "rm -rf sample_data\n",
        "rm -rf fairseq"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj9kQGm4RKbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6341025-c330-4a54-b56d-0bb2d186b499"
      },
      "source": [
        "%%bash\n",
        "rm -rf sample_data\n",
        "pip install tqdm boto3 requests regex sentencepiece sacremoses transformers easyocr\n",
        "pip install mosestokenizer indic-nlp-library mock sacrebleu tensorboardX pyarrow subword-nmt\n",
        "git clone https://github.com/pytorch/fairseq.git\n",
        "cd fairseq\n",
        "pip install --editable ./\n",
        "%cd ..\n",
        "# pip install fairseq\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.18.26)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.45)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.7/dist-packages (1.4)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.26 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.26)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.26->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.26->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.26->boto3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.9.0+cu102)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.1.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from easyocr) (4.1.2.30)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.10.0+cu102)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.4.1)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.10.0)\n",
            "Requirement already satisfied: mosestokenizer in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.7/dist-packages (0.81)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (4.0.3)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: openfile in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (0.0.7)\n",
            "Requirement already satisfied: uctools in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (1.3.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (0.6.2)\n",
            "Requirement already satisfied: toolwrapper in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (2.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.19.5)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (0.2.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.3.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic-nlp-library) (1.8.5)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.9.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.16)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.4.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.62.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.3.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (4.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.2)\n",
            "Requirement already satisfied: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (2.0.6)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core->fairseq) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core->fairseq) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.5.0)\n",
            "Installing collected packages: dataclasses, fairseq\n",
            "Successfully installed dataclasses-0.6 fairseq-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgd_SddtB1Fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23130611-3a06-41dd-a833-a04c51aa5c6c"
      },
      "source": [
        "# clone the repo for running evaluation\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 498, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 498 (delta 160), reused 132 (delta 117), pack-reused 297\u001b[K\n",
            "Receiving objects: 100% (498/498), 1.49 MiB | 10.08 MiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n",
            "/content/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1325, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 1325 (delta 84), reused 89 (delta 41), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1325/1325), 9.57 MiB | 12.51 MiB/s, done.\n",
            "Resolving deltas: 100% (688/688), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 31.97 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 1 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 2.93 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEO_HZxSIDvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06f2a1c-08d7-493b-ee33-b1d400d2dd06"
      },
      "source": [
        "%%bash\n",
        "# downloading the indic-indic model\n",
        "wget https://storage.googleapis.com/samanantar-public/V0.3/models/indic-en.zip\n",
        "unzip indic-en.zip\n",
        "rm indic-en.zip\n",
        "wget https://storage.googleapis.com/samanantar-public/V0.3/models/m2m.zip\n",
        "unzip m2m.zip\n",
        "rm m2m.zip\n",
        "\n",
        "# %cd indicTrans"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  indic-en.zip\n",
            "   creating: indic-en/\n",
            "   creating: indic-en/vocab/\n",
            "  inflating: indic-en/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: indic-en/vocab/vocab.SRC  \n",
            "  inflating: indic-en/vocab/vocab.TGT  \n",
            "  inflating: indic-en/vocab/bpe_codes.32k.TGT  \n",
            "   creating: indic-en/final_bin/\n",
            "  inflating: indic-en/final_bin/preprocess.log  \n",
            "  inflating: indic-en/final_bin/dict.TGT.txt  \n",
            "  inflating: indic-en/final_bin/test.SRC-TGT.SRC.idx  \n",
            "  inflating: indic-en/final_bin/test.SRC-TGT.TGT.idx  \n",
            "  inflating: indic-en/final_bin/train.SRC-TGT.SRC.idx  \n",
            "  inflating: indic-en/final_bin/dict.SRC.txt  \n",
            "  inflating: indic-en/final_bin/valid.SRC-TGT.TGT.idx  \n",
            "  inflating: indic-en/final_bin/test.SRC-TGT.TGT.bin  \n",
            "  inflating: indic-en/final_bin/valid.SRC-TGT.TGT.bin  \n",
            "  inflating: indic-en/final_bin/train.SRC-TGT.TGT.idx  \n",
            "  inflating: indic-en/final_bin/train.SRC-TGT.TGT.bin  \n",
            "  inflating: indic-en/final_bin/valid.SRC-TGT.SRC.idx  \n",
            "  inflating: indic-en/final_bin/train.SRC-TGT.SRC.bin  \n",
            "  inflating: indic-en/final_bin/valid.SRC-TGT.SRC.bin  \n",
            "  inflating: indic-en/final_bin/test.SRC-TGT.SRC.bin  \n",
            "   creating: indic-en/model/\n",
            "  inflating: indic-en/model/checkpoint_best.pt  \n",
            "Archive:  m2m.zip\n",
            "   creating: m2m/\n",
            "   creating: m2m/vocab/\n",
            "  inflating: m2m/vocab/vocab.SRC     \n",
            "  inflating: m2m/vocab/vocab.TGT     \n",
            "  inflating: m2m/vocab/bpe_codes.32k.SRC_TGT  \n",
            "   creating: m2m/final_bin/\n",
            "  inflating: m2m/final_bin/dict.TGT.txt  \n",
            "  inflating: m2m/final_bin/dict.SRC.txt  \n",
            "   creating: m2m/model/\n",
            "  inflating: m2m/model/checkpoint_best.pt  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7GH6IwoSkFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d26f5f1-6633-4fe6-d251-0102823f7872"
      },
      "source": [
        "!pwd\n",
        "!cp /content/m2m/vocab/bpe_codes.32k.SRC_TGT /content/m2m/vocab/bpe_codes.32k.SRC\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ODkLZn70ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f85820a-6b8a-4f39-cc5d-eb809c226136"
      },
      "source": [
        "%%bash\n",
        "apt-get install python-numpy libicu-dev\n",
        "pip install pyicu pycld2 morfessor \n",
        "pip install polyglot\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-numpy is already the newest version (1:1.13.3-2ubuntu1).\n",
            "python-numpy set to manually installed.\n",
            "libicu-dev is already the newest version (60.2-3ubuntu3.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Collecting pyicu\n",
            "  Downloading PyICU-2.7.4.tar.gz (298 kB)\n",
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (2.0.6)\n",
            "Building wheels for collected packages: pyicu, pycld2\n",
            "  Building wheel for pyicu (setup.py): started\n",
            "  Building wheel for pyicu (setup.py): finished with status 'done'\n",
            "  Created wheel for pyicu: filename=PyICU-2.7.4-cp37-cp37m-linux_x86_64.whl size=1374693 sha256=f3f904ffe0f8629c0964d85f71599443f0f2b8b149de5e95f714679ecc20644b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/3a/c8/2d2397cd8f6cd04489ecac3d1e6821bb4938d73312d69b834f\n",
            "  Building wheel for pycld2 (setup.py): started\n",
            "  Building wheel for pycld2 (setup.py): finished with status 'done'\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834148 sha256=9ffd5d7afaa66860a40435604f239d1998c658303e29f1a6c6f27156ae017ee2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/e4/58/ed2e9f43c07d617cc81fe7aff0fc6e42b16c9cf6afe960b614\n",
            "Successfully built pyicu pycld2\n",
            "Installing collected packages: pyicu, pycld2\n",
            "Successfully installed pycld2-0.41 pyicu-2.7.4\n",
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "Building wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py): started\n",
            "  Building wheel for polyglot (setup.py): finished with status 'done'\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52578 sha256=ebecf62bee08a0e9fdcd422fcd63869f28a67d8016748e4527f836831843de74\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/bc/67/75c9de8e9726460bc0b101ad225ad025cb8ce9e0759beb9d52\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xm_h0nvGBVO",
        "outputId": "2078a7d0-8459-44c3-da31-2d02e6fae920"
      },
      "source": [
        "!polyglot download embeddings2.en transliteration2.ar\n",
        "!polyglot download transliteration2.kn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package embeddings2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package transliteration2.ar to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package transliteration2.kn to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62cg57vhfNvX"
      },
      "source": [
        "# !rm indic-en.zip m2m.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJhyh2GPFuA"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import easyocr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iADWYL3I3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f683135a-d432-4694-c1b1-41e5f7ea34ef"
      },
      "source": [
        "reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRXzV8Sy4VP8"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-uaOYWC5BQE"
      },
      "source": [
        "image_root_path = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "kannada_img_file = image_root_path + 'kannada_01.jpg'\n",
        "kannada_img_file_1 = '/content/drive/MyDrive/Colab Notebooks/kannada_01.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IugWk3WK6phD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8af5c42-40f4-4e6e-e904-6bd7c6ac6dbc"
      },
      "source": [
        "result = reader.readtext(kannada_img_file, detail = 0)\n",
        "with open('ka.txt', 'w') as f:\n",
        "    f.write(str(result))\n",
        "\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['|.ಹೊಂದಿಸಿ ಬರೆಯಿರಿ:',\n",
              " '೧.ಕಾಪಾಡು',\n",
              " 'ಹನಿ',\n",
              " '೨',\n",
              " 'ಬುದ್ದಿವಂತ',\n",
              " 'ಸಂರಕ್ಷಿಸು',\n",
              " '೩.ಮಳೆ',\n",
              " 'ಆಸನ',\n",
              " '೪',\n",
              " 'ಬೆಟ್ಟ',\n",
              " 'ರಾಮಕೃಷ್ಣ',\n",
              " '೫ ಪೀಠ',\n",
              " 'ಗುಡ್ಡ',\n",
              " 'Iಆವರಣದಲ್ಲಿ ಕೊಟ್ಟಿರುವ ಸರಿಯಾದ ಉತ್ತರವನ್ನು ಆರಿಸಿ ಬಿಟ್ಟ ಸ್ಥಳದಲ್ಲಿ ಬರೆಯಿರಿ:',\n",
              " '(ಕುವೆಂಪು, ಅಪ್ಪುಗೆ, ಪಂಡಿತರು,',\n",
              " 'ತ,ಮಳೆ',\n",
              " '೧',\n",
              " '.ಕೃಷ್ಣದೇವರಾಯನ ಆಸ್ಥಾನದಲ್ಲಿ',\n",
              " 'ಇದ್ದರು.',\n",
              " '೨.ನೀರಿನ ಮೂಲ',\n",
              " 'ಸಂಸ್ಕೃ ತ']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjq244h16Yep"
      },
      "source": [
        "# from transformers import AutoTokenizer, AutoModel\n",
        "  \n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\", keep_accents=True)\n",
        "\n",
        "# model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSqFxhFa_C9f"
      },
      "source": [
        "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6laCrqKuCLjx"
      },
      "source": [
        "# !bash ./indicTrans/joint_translate.sh ka.txt en_outputs.txt 'kn' 'en' './indic-en'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52fxyGvQEmna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200e7056-131a-4547-e99f-eb0015fc4277"
      },
      "source": [
        "# we need to be in indicTrans directory for translation model to load\n",
        "%cd /content/indicTrans/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa1gUjfdFDDh"
      },
      "source": [
        "# !bash joint_translate.sh /content/ka.txt en_outputs.txt 'kn' 'en' '../indic-en'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvlHgj7eFHaA"
      },
      "source": [
        "# !cat en_outputs.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh7qxqokF1Nc"
      },
      "source": [
        "# from indicTrans.inference.engine import Model\n",
        "\n",
        "# indic2en_model = Model(expdir='/content/indic-en')\n",
        "# indic2en_model.batch_translate(result, 'kn', 'en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUphjMRwHUzs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z_NbNAORazg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f805788-a753-4caf-ddcc-e305fd760d7f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuglbhkoRj2N"
      },
      "source": [
        "# !cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvPjpZqxRqv4"
      },
      "source": [
        "!cd \n",
        "!cd /content/indicTrans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmf94Kr5NzzK"
      },
      "source": [
        "from indicTrans.inference.engine import Model\n",
        "# indicm2m_model = Model(expdir='/content/m2m')\n",
        "# indicm2m_model.batch_translate(result, 'kn', 'hi')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCC479uuveKc"
      },
      "source": [
        "def KannadaImageToHindiText(kannada_img_file):\n",
        "  import torch\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt  \n",
        "  import easyocr\n",
        "  from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
        "  from indicTrans.inference.engine import Model\n",
        "\n",
        "  reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory\n",
        "  result = reader.readtext(kannada_img_file, detail = 0)\n",
        "  indicm2m_model = Model(expdir='/content/m2m')\n",
        "  return indicm2m_model.batch_translate(result, 'kn', 'hi')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVVWzToEQRKc"
      },
      "source": [
        "def cleanTransliterText(transliter_text):\n",
        "  blank = ['',\"\", \" \", ' ', '\\t']\n",
        "  s_list = []\n",
        "  for x in transliter_text:\n",
        "    if x not in blank:\n",
        "      s_list.append(x)\n",
        "  return s_list\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gDGLe7WMrtY"
      },
      "source": [
        "def getTextFromImage(image_file):\n",
        "  import torch\n",
        "  import numpy as np\n",
        "  import easyocr\n",
        "  reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory\n",
        "  result = reader.readtext(image_file, detail = 0)\n",
        "  return result"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "Hvv9fTj6z_vb",
        "outputId": "4b5a0433-475d-4d3f-a142-6882f1583ebb"
      },
      "source": [
        "# KannadaImageToHindiText(kannada_img_file_1)\n",
        "%cd\n",
        "%cd /content/indicTrans/\n",
        "%pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content/indicTrans\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/indicTrans'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h7JBvtS0FRK"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  \n",
        "import easyocr\n",
        "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
        "from indicTrans.inference.engine import Model\n",
        "\n",
        "class KannadaToHindi :\n",
        "  def __init__(self):\n",
        "    self.reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory\n",
        "    self.indicm2m_model = Model(expdir='/content/m2m')\n",
        "\n",
        "  def TranslateKannadaImageToHindi(self, kannada_img_file):\n",
        "    result = self.reader.readtext(kannada_img_file, detail = 0)\n",
        "    return self.indicm2m_model.batch_translate(result, 'kn', 'hi')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaaLw_0E1cDe",
        "outputId": "18c37d1c-7273-48e0-919c-c0ecf60055d7"
      },
      "source": [
        "traslator = KannadaToHindi()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnmfdr2S1nHK"
      },
      "source": [
        "kannada_img_file_1 = '/content/drive/MyDrive/Colab Notebooks/kannada_01.jpg'\n",
        "traslator.TranslateKannadaImageToHindi(kannada_img_file_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoO2xHCx16Hv"
      },
      "source": [
        "kannada_img_file_2 = '/content/drive/MyDrive/Colab Notebooks/kannada_02.jpg'\n",
        "traslator.TranslateKannadaImageToHindi(kannada_img_file_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF5OAAsT5msc"
      },
      "source": [
        "kannada_img_file = '/content/drive/MyDrive/Colab Notebooks/kannada_03.jpg'\n",
        "traslator.TranslateKannadaImageToHindi(kannada_img_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCp_4kEj6R3z"
      },
      "source": [
        "kannada_img_file = '/content/drive/MyDrive/Colab Notebooks/kannada_04.jpg'\n",
        "traslator.TranslateKannadaImageToHindi(kannada_img_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwqZ8Th_GzvB",
        "outputId": "4fb8d665-ac87-4e92-ecaf-8fa62e3e4489"
      },
      "source": [
        "from polyglot.downloader import downloader\n",
        "# print(downloader.supported_languages_table(\"transliteration2\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1. Italian                    2. Hindi                      3. French                   \n",
            "  4. Spanish; Castilian         5. Vietnamese                 6. Arabic                   \n",
            "  7. Macedonian                 8. Bosnian-Croatian-Serbian   9. Norwegian Nynorsk        \n",
            " 10. Azerbaijani               11. Bulgarian                 12. Georgian                 \n",
            " 13. Galician                  14. Amharic                   15. Yiddish                  \n",
            " 16. Norwegian                 17. Estonian                  18. Japanese                 \n",
            " 19. Haitian; Haitian Creole   20. Belarusian                21. Greek, Modern            \n",
            " 22. Welsh                     23. Albanian                  24. Marathi (Marāṭhī)        \n",
            " 25. Armenian                  26. Slovene                   27. Korean                   \n",
            " 28. Irish                     29. Bengali                   30. Serbian                  \n",
            " 31. Finnish                   32. Catalan; Valencian        33. Croatian                 \n",
            " 34. Dutch                     35. Swedish                   36. Tagalog                  \n",
            " 37. Danish                    38. Kannada                   39. Maltese                  \n",
            " 40. Swahili                   41. Latvian                   42. Telugu                   \n",
            " 43. Ukrainian                 44. Romanian, Moldavian, ...  45. Persian                  \n",
            " 46. Latin                     47. Slovak                    48. Icelandic                \n",
            " 49. Portuguese                50. Urdu                      51. Gujarati                 \n",
            " 52. Tamil                     53. Khmer                     54. Malay                    \n",
            " 55. Afrikaans                 56. Basque                    57. Polish                   \n",
            " 58. German                    59. Esperanto                 60. Indonesian               \n",
            " 61. Chinese                   62. Czech                     63. Hebrew (modern)          \n",
            " 64. Lithuanian                65. Turkish                   66. Bosnian                  \n",
            " 67. Hungarian                 68. Thai                      69. Russian                  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXuS5GbbMA3Y",
        "outputId": "d2bcfcd7-367f-4e6c-f60a-4116a30137c4"
      },
      "source": [
        "from polyglot.text import Text\n",
        "\n",
        "kannada_img_file = '/content/drive/MyDrive/Colab Notebooks/kannada_04.jpg'\n",
        "image_text = str(getTextFromImage( kannada_img_file))\n",
        "text = Text(image_text)\n",
        "transliter_text = text.transliterate(\"en\")\n",
        "trans_str = \" \".join(cleanTransliterText(transliter_text))\n",
        "print(trans_str)\n",
        "# for x in text.transliterate(\"en\"):\n",
        "#   print(x)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "prashneglige erdu muru wakyadlli vidasagrn mukh arlitu ramkrishna vidasagrnondige wad madlu karna vidasagrn mukh arlitu mhishbndn endrenu endre elelin kddiglu mhishbndhn endre eamme kttuv hgg ide mhishbndhnd arth kottiruv matnnu aru arige helidru visha modle tilididdre nanu illige bruttle matnnu vidasagr krishnadevraanige helidnu idu nammurin dnkaauv hudugrigu gottu matnnu tenali ramkrishna vidasagrnige helidnu kelgin kvigl pricha madi kuvenpu purna hesru kuppleli venktpp puttpp jnn sthl shivmogg jillea kuppleli irlill\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtdCYw-mRpFR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  \n",
        "import easyocr\n",
        "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
        "from indicTrans.inference.engine import Model\n",
        "from polyglot.text import Text\n",
        "\n",
        "class KannadaToHindi :\n",
        "  def __init__(self):\n",
        "    self.reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory\n",
        "    self.indicm2m_model = Model(expdir='/content/m2m')\n",
        "\n",
        "\n",
        "  def getTextFromImage(self, image_file):\n",
        "    reader = easyocr.Reader(['kn','en']) # need to run only once to load model into memory\n",
        "    result = reader.readtext(image_file, detail = 0)\n",
        "    return result\n",
        "\n",
        "  def cleanTransliterText(self, transliter_text):\n",
        "    blank = ['',\"\", \" \", ' ', '\\t']\n",
        "    s_list = []\n",
        "    for x in transliter_text:\n",
        "      if x not in blank:\n",
        "        s_list.append(x)\n",
        "    return s_list\n",
        "\n",
        "  def getTransliterredText(self,text_from_image):\n",
        "    image_text = str(text_from_image)\n",
        "    text = Text(image_text)\n",
        "    transliter_text = text.transliterate(\"en\")\n",
        "    trans_str = \" \".join(cleanTransliterText(transliter_text))\n",
        "    return trans_str\n",
        "\n",
        "  def TranslateKannadaImageToHindi(self, kannada_img_file):\n",
        "    text_from_image = self.reader.readtext(kannada_img_file, detail = 0)\n",
        "    transliterred_result = self.getTransliterredText(text_from_image)\n",
        "    translated_result = self.indicm2m_model.batch_translate(text_from_image, 'kn', 'hi')\n",
        "    return translated_result, transliterred_result\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGnpu8-Tzhn5",
        "outputId": "281d4538-fcf9-4309-f33f-a9df808e58e2"
      },
      "source": [
        "kannada_img_file = '/content/drive/MyDrive/Colab Notebooks/kannada_04.jpg'\n",
        "transcode = KannadaToHindi()\n",
        "translated, translittered = transcode.TranslateKannadaImageToHindi(kannada_img_file)\n",
        "print(translittered)\n",
        "print(translated)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:00<00:00, 9326.60it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(['नीचे दिए गए प्रश्नों के लिए दो/तीन पंक्ति में', 'विद्यासागर का चेहरा क्यों फूला?', 'उथेनाली रामकृष्ण विद्यासागर से बहस करने के लिए सहमत हुई', 'विद्यासागर का चेहरा फूट पड़ा', 'तिलकस्थ महिषाबंदन क्या है?', '0:', 'तिलकाष्ठा', '\"\" \"\" \"\" \"बैल की छड़ियां\" \"\" \"और\" \"\" \"महिषबंधन\" \"\" \"यानि बैल की रस्सी\" \"\"', 'तिलकत्था महिषाबंधन का अर्थ', 'ग्यारहवीं का वादा किसने किया?', 'यह विषय पहले से है', 'अगर मैं जानता हूं तो यहां आऊंगा।', 'जवाबः इस', 'विद्यासागर ने कृष्णदेवराय से कहा था -', 'हमारे पशुपालक भी यह जानते हैं।', 'उत्तरः यह', 'तेनाली रामकृष्ण ने विद्यासागर से कहा था -', 'बारहवें कवियों का परिचय देंः', '[शानदार]', 'पूरा नाम: कुप्पली वेंकटप्पा पुट्टप्पा', 'पैदा हुआ।', '29', '12', '1904', 'स्थान (P)', 'शिवमोगा जिले के कुपली', 'जवाब दीजिएः', 'नहीं था।'], 'prashneglige erdu muru wakyadlli vidasagrn mukh arlitu ramkrishna vidasagrnondige wad madlu karna vidasagrn mukh arlitu mhishbndn endrenu endre elelin kddiglu mhishbndhn endre eamme kttuv hgg ide mhishbndhnd arth kottiruv matnnu aru arige helidru visha modle tilididdre nanu illige bruttle matnnu vidasagr krishnadevraanige helidnu idu nammurin dnkaauv hudugrigu gottu matnnu tenali ramkrishna vidasagrnige helidnu kelgin kvigl pricha madi kuvenpu purna hesru kuppleli venktpp puttpp jnn sthl shivmogg jillea kuppleli irlill')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThiQMKfZ3_Eo",
        "outputId": "72a414c5-3f2c-4f6d-d4de-0a4c540adc04"
      },
      "source": [
        "kannada_img_file = '/content/drive/MyDrive/Colab Notebooks/kannada_03.jpg'\n",
        "translated, translittered = transcode.TranslateKannadaImageToHindi(kannada_img_file)\n",
        "print(translittered)\n",
        "print(translated)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 8628.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wakyadlli bisil niru niru aviaaitu mod awag bharwaaitu avi tnidu bharwaaitu vidasagrnondige wad madlu aru vidasagrnondige wad madlu tenali ramkrishna tenali ramkrishna wadkke av grnthvnnu arisikondnu ramkrishna wadkke mhishbndhn enb grnthvnnu arisikondnu knndd knd avudnnu mreabardu knd knndvnnu mreabardu\n",
            "['एक वाक्य में', 'गर्म पानी का क्या हुआ?', 'गर्मी का पानी भाप बन गया।', '2 में से', 'बादल कब भारी हुआ?', 'उष्मायन वातावरण ठंडा हो गया।', 'कौन विद्यासागर से बहस करने के लिए सहमत हुआ?', 'उत्तरः -', 'तेनाली रामकृष्ण विद्यासागर के साथ बहस करने के लिए सहमत हुए', '4 टेनाली', 'रामकृष्ण ने किस ग्रंथ का चयन किया?', 'उन्होंने उतेनाली रामकृष्ण वाद के लिए तिलकस्थ महिषाबंधन नामक पुस्तक का चयन किया।', 'यह संख्या 5 है', 'हिंदी के प्रति हमें क्या याद रखना चाहिए?', 'कन्नड़ भाषा को न भूलेंः', 'जवाब दीजिएः']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxB073084crc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}